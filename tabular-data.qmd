---
title: "Module 1: Tabular Data"
subtitle: "Working with larger-than-RAM data using duckdbfs"
author: "ESPM 288"
format: html:
  embed-resources: true
---

## Introduction

In this module, we will explore high-performance workflows for tabular data. We will use `duckdbfs` to work with datasets that are larger than available RAM by leveraging DuckDB's streaming and remote file access capabilities.

## Case Study: Global Supply Chains

We will be working with [EXIOBASE 3.8.1](https://source.coop/youssef-harby/exiobase-3), a global Multi-Regional Input-Output (MRIO) database. This dataset tracks economic transactions between sectors and regions, along with their environmental impacts (emissions, resource use, etc.).

**Data description:**
- **Coverage**: 44 countries + 5 rest-of-world regions.
- **Timeframe**: 1995â€“2022.
- **Content**: Economic transactions (Z matrix), final demand (Y matrix), and environmental stressors (F matrix).
- **Format**: Cloud-optimized Parquet, partitioned by year and matrix type.

## Setup

```{r}
library(duckdbfs)
library(dplyr)
library(tidyr)
library(ggplot2)
```

## Exercise 1: connecting to remote data

We can open the entire dataset without downloading it using `open_dataset()`. The data is hosted on Source Cooperative. The `**` pattern allows recursive scanning of the partitioned parquet files.

```{r}
# Remote S3 path to EXIOBASE 3 (Source Cooperative)

duckdbfs::duckdb_secrets(
    key = "",
    secret = "",
    endpoint = "s3.amazonaws.com",
    region = "us-west-2"
)
s3_url <- "s3://us-west-2.opendata.source.coop/youssef-harby/exiobase-3/4588235/parquet/year=*/format=ixi/matrix=F_impacts/**"

# Open the dataset lazily
exio <- open_dataset(s3_url)

# View the schema (column names and types) without reading data
glimpse(exio)
```

## Exercise 2: Efficient Filtering
The dataset is large. We should filter *before* collecting any data into R.
US 2022 filter
```{r}
exio |>
    filter(year == 2022, region == "US") |>
    head() |> # view the first 6 rows
    collect()
```

## What happened globally in 1995? What countries and sectors were the biggest emitters?
```{r}
exio |>
    filter(year == 1995) |>
    group_by(region) |>
    summarize(total_emissions = sum(.data$value, na.rm = TRUE), .groups = "drop") |>
    arrange(desc(total_emissions)) |>
    head(20) |>
    collect()
```



> **Task**
: Construct a query to find the top 5 sectors in the US by CO2 emissions in 2022. Remember to check the column names in `exio` to find the appropriate emissions flow.

```{r}
#a query written based on the task above, used the chatbot and the info provide in the glimpse. schema problem was in the initial url

exio |>
  distinct(stressor) |>
  collect()


exio |>
  filter(year == 2022, region == "US") |>
  group_by(sector) |>
  summarize(total_co2 = sum(.data$value, na.rm = TRUE), .groups = "drop") |>
  slice_max(order_by = total_co2, n = 5) |>
  collect()
```

## Visualization: Top 10 Sectors by CO2 Emissions

```{r}
# Get top 10 sectors by CO2 emissions
top10_sectors <- exio |>
  filter(year == 2022, region == "US") |>
  group_by(sector) |>
  summarize(total_co2 = sum(.data$value, na.rm = TRUE), .groups = "drop") |>
  slice_max(order_by = total_co2, n = 10) |>
  collect()

# Create the visualization
p <- ggplot(top10_sectors, aes(x = reorder(sector, total_co2), y = total_co2)) +
  geom_col(fill = "#FF10F0") +
  coord_flip() +
  labs(
    title = "Top 10 Sectors by CO2 Emissions in the US (2022)",
    x = "Sector",
    y = "Total CO2 Emissions"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 8))

# Display the plot
print(p)

# Export the visualization
ggsave("top10_sectors_co2.png", plot = p, width = 10, height = 6, dpi = 300)
```

next task: explore data, which sectors/countries are experiencing decreasing emissions? why is the data weird in the first year?